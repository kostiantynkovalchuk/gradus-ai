Delete old RAG data and reingest company websites with AVTD â†’ Best Brands enrichment.

CRITICAL CONTEXT:
Company just rebranded AVTD â†’ Best Brands (with space!). Websites still mention AVTD (not updated yet), but Maya should speak about Best Brands as the progressive AI voice. We need to enrich scraped content to replace AVTD mentions with Best Brands before ingesting.

PHASE 1: DELETE OLD DATA

Create script: backend/scripts/cleanup_old_rag_data.py
```python
import os
from pinecone import Pinecone
from dotenv import load_dotenv

load_dotenv()

def delete_old_company_data():
    """Delete old AVTD and brand website data from Pinecone"""
    
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    index = pc.Index(os.getenv("PINECONE_INDEX_NAME"))
    
    print("ğŸ—‘ï¸ Deleting old company website data...")
    
    try:
        # Delete old company websites (keep Wikipedia!)
        index.delete(
            filter={
                "source_type": {"$in": ["company_website", "brand_website"]}
            },
            namespace="company_knowledge"
        )
        print("âœ… Deleted old company website data")
        
    except Exception as e:
        print(f"âŒ Error deleting data: {e}")
    
    stats = index.describe_index_stats()
    print(f"ğŸ“Š Remaining vectors: {stats}")

if __name__ == "__main__":
    delete_old_company_data()
```

PHASE 2: BATCH SCRAPE WITH REBRAND ENRICHMENT

Create script: backend/scripts/batch_ingest_websites.py
```python
import asyncio
import os
import re
from datetime import datetime
from services.carousel_scraper import scrape_website_with_carousels
from services.rag_service import add_documents_to_rag
from dotenv import load_dotenv

load_dotenv()

# Websites to scrape
WEBSITES = [
    {"url": "https://avtd.com/", "name": "Best Brands Main", "brand": "Best Brands", "type": "distributor"},
    {"url": "https://www.dovbush.com.ua/", "name": "DOVBUSH", "brand": "DOVBUSH", "type": "cognac"},
    {"url": "https://greendayvodka.com/uk/", "name": "Green Day", "brand": "GREENDAY", "type": "vodka"},
    {"url": "https://villaua.com/", "name": "Villa", "brand": "VILLA", "type": "wine"},
    {"url": "https://helsinki.ua/", "name": "Helsinki", "brand": "HELSINKI", "type": "vodka"},
    {"url": "https://ukrainka.ua/", "name": "UKRAINKA", "brand": "UKRAINKA", "type": "vodka"},
    {"url": "https://wineviaggio.com/", "name": "Wineviaggio", "brand": "WINEVIAGGIO", "type": "wine"},
    {"url": "https://marlinvodka.com/indexUK.html", "name": "Marlin", "brand": "MARLIN", "type": "vodka"},
    {"url": "https://kristivalley.com/", "name": "Kristi Valley", "brand": "KRISTI VALLEY", "type": "wine"},
    {"url": "https://adjari.com.ua/index1.html", "name": "Adjari", "brand": "ADJARI", "type": "cognac"},
    {"url": "https://didilari.com/", "name": "Didi Lari", "brand": "DIDI LARI", "type": "wine"}
]

def enrich_content_with_rebrand(content: str, brand: str) -> str:
    """
    Replace AVTD mentions with Best Brands.
    Websites still say AVTD, but Maya should use Best Brands!
    """
    
    # Replace all AVTD variants with "Best Brands"
    replacements = {
        "AVTD": "Best Brands",
        "ĞĞ’Ğ¢Ğ”": "Best Brands",
        "ĞĞ’ Ğ¢Ğ”": "Best Brands",
        "Ğ¢Ğ” ĞĞ’": "Best Brands",
        "Ğ¢Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ¸Ğ¹ Ğ”Ñ–Ğ¼ ĞĞ’": "Best Brands",
        "Ğ¢Ğ” Â«ĞĞ’Â»": "Best Brands",
        "TD AV": "Best Brands",
        "ĞĞ’ Group": "Best Brands",
        "BestBrands": "Best Brands",  # In case old branding without space exists
    }
    
    enriched = content
    for old, new in replacements.items():
        # Case-insensitive replacement
        enriched = re.sub(
            re.escape(old), 
            new, 
            enriched, 
            flags=re.IGNORECASE
        )
    
    # Add brand context enrichment
    enrichment = f"""

[COMPANY CONTEXT: {brand} is distributed by Best Brands, Ukraine's largest alcohol distributor with 40,000+ retail points. Best Brands (formerly AVTD) represents premium brands across vodka, cognac, and wine categories.]
"""
    
    return enriched + enrichment

async def scrape_single_website(website_info):
    """Scrape and enrich a single website"""
    print(f"\nğŸ” Scraping {website_info['name']} ({website_info['url']})...")
    
    try:
        # Scrape with carousel click-through
        content = await scrape_website_with_carousels(website_info['url'])
        
        if content:
            # ENRICH: Replace AVTD â†’ Best Brands
            enriched_content = enrich_content_with_rebrand(
                content, 
                website_info['brand']
            )
            
            print(f"âœ… Scraped {website_info['name']}: {len(content)} chars")
            print(f"   ğŸ“ Enriched with Best Brands context")
            
            return {
                "content": enriched_content,
                "metadata": {
                    "source": website_info['url'],
                    "source_type": "company_website",
                    "brand": website_info['brand'],
                    "category": website_info['type'],
                    "company": "Best Brands",
                    "enriched": True,
                    "scraped_at": datetime.now().isoformat()
                }
            }
        else:
            print(f"âš ï¸ No content from {website_info['name']}")
            return None
            
    except Exception as e:
        print(f"âŒ Error scraping {website_info['name']}: {e}")
        return None

async def batch_scrape_websites():
    """Scrape all websites sequentially"""
    print("ğŸš€ Starting batch scraping with rebrand enrichment...")
    print(f"ğŸ“Š Total websites: {len(WEBSITES)}")
    
    results = []
    for i, website in enumerate(WEBSITES, 1):
        print(f"\n[{i}/{len(WEBSITES)}] Processing {website['name']}...")
        result = await scrape_single_website(website)
        if result:
            results.append(result)
        await asyncio.sleep(3)  # Polite delay
    
    print(f"\nğŸ“Š Scraped {len(results)}/{len(WEBSITES)} websites successfully")
    return results

def ingest_to_rag(scraped_data):
    """Ingest enriched data to Pinecone"""
    print("\nğŸ“¤ Ingesting to RAG...")
    
    success_count = 0
    for item in scraped_data:
        try:
            add_documents_to_rag(
                documents=[{
                    "content": item["content"],
                    "metadata": item["metadata"]
                }],
                namespace="company_knowledge"
            )
            print(f"âœ… Ingested {item['metadata']['brand']}")
            success_count += 1
            
        except Exception as e:
            print(f"âŒ Error ingesting {item['metadata']['brand']}: {e}")
    
    print(f"\nğŸ“Š Ingested {success_count}/{len(scraped_data)} successfully")

async def main():
    """Main batch processing"""
    print("=" * 60)
    print("ğŸ­ BATCH WEBSITE INGESTION - BEST BRANDS REBRAND")
    print("=" * 60)
    
    # Scrape with enrichment
    scraped_data = await batch_scrape_websites()
    
    if not scraped_data:
        print("âŒ No data scraped")
        return
    
    # Ingest to RAG
    ingest_to_rag(scraped_data)
    
    print("\n" + "=" * 60)
    print("âœ… BATCH INGESTION COMPLETE!")
    print(f"ğŸ“Š Processed {len(scraped_data)}/{len(WEBSITES)} websites")
    print("ğŸ”„ All AVTD mentions replaced with Best Brands")
    print("=" * 60)

if __name__ == "__main__":
    asyncio.run(main())
```

PHASE 3: CREATE RUN SCRIPT

Create: backend/scripts/run_rag_update.sh
```bash
#!/bin/bash

echo "ğŸš€ Starting RAG Update with Best Brands Rebrand..."
echo ""

# Delete old data
echo "ğŸ“ Step 1: Deleting old data..."
python3 backend/scripts/cleanup_old_rag_data.py

echo ""
echo "â° Waiting 3 seconds..."
sleep 3

# Scrape and ingest with enrichment
echo ""
echo "ğŸ“ Step 2: Scraping 11 websites with Best Brands enrichment..."
echo "â° This will take 10-15 minutes..."
python3 backend/scripts/batch_ingest_websites.py

echo ""
echo "âœ… RAG Update Complete!"
echo "ğŸ¯ Maya now speaks about Best Brands!"
```

Make executable:
```bash
chmod +x backend/scripts/run_rag_update.sh
```

PHASE 4: COMMIT
```bash
git add backend/scripts/
git commit -m "Add batch RAG update with AVTDâ†’Best Brands enrichment"
git push origin main
```

USAGE:
```bash
./backend/scripts/run_rag_update.sh
```

KEY FEATURES:
âœ… Scrapes websites (still contain "AVTD")
âœ… Enriches content: replaces AVTD â†’ Best Brands (with space!)
âœ… Adds company context to each brand
âœ… Maya will say "Best Brands" even though websites say "AVTD"
âœ… Handles Ukrainian and English AVTD variants
âœ… Maintains brand-specific information

EXPECTED BEHAVIOR AFTER INGESTION:
User: "Ğ¯ĞºÑ– Ğ±Ñ€ĞµĞ½Ğ´Ğ¸ Ñ” Ğ² AVTD?"
Maya: "Ğ’ Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»Ñ– Best Brands Ñ” Ğ¿Ñ€ĞµĞ¼Ñ–ÑƒĞ¼ Ğ±Ñ€ĞµĞ½Ğ´Ğ¸..."

User: "Tell me about GREENDAY"
Maya: "GREENDAY - Ñ†Ğµ Ğ¿Ñ€ĞµĞ¼Ñ–ÑƒĞ¼ Ğ³Ğ¾Ñ€Ñ–Ğ»ĞºĞ° Ğ²Ñ–Ğ´ Best Brands..."

Maya is the progressive voice using the new brand name with correct spacing! ğŸš€